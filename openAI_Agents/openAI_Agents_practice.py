import os
import asyncio
from contextlib import AsyncExitStack
from openai import AsyncOpenAI, OpenAI
from openai.types.responses import ResponseTextDeltaEvent
from agents import OpenAIChatCompletionsModel, Agent, Runner, set_default_openai_client, set_tracing_disabled, \
    function_tool, TResponseInputItem, ItemHelpers
from agents.model_settings import ModelSettings
from agents.mcp import MCPServer, MCPServerStdio, MCPServerSse, MCPServerStreamableHttp

from rich import print
from rich.markdown import Markdown
from typing import Literal
import base64
import pathlib
from pydantic import BaseModel


# ç”±äºAgents SDKé»˜è®¤æ”¯æŒçš„æ¨¡å‹æ˜¯OpenAIçš„GPTç³»åˆ—ï¼Œå› æ­¤åœ¨ä¿®æ”¹åº•å±‚æ¨¡å‹çš„æ—¶å€™ï¼Œéœ€è¦å°†custom_client è®¾ç½®ä¸ºï¼šset_default_openai_client(external_client)

def custom2default_openai_model(model: str, base_url: str, api_key: str, ):
    custom_client = AsyncOpenAI(base_url=base_url, api_key=api_key)
    set_default_openai_client(custom_client)
    # we disable tracing under the assumption that you don't have an API key
    # from platform.openai.com. If you do have one, you can either set the `OPENAI_API_KEY` env var
    # or call set_tracing_export_api_key() to set a tracing specific key
    set_tracing_disabled(disabled=True)  # ä¸åœ¨platform.openai.comä¸Štrace
    default_openai_model = OpenAIChatCompletionsModel(model=model, openai_client=custom_client)
    return default_openai_model


async def agents_async_chat_once(agent: Agent, input_items: list[TResponseInputItem] | TResponseInputItem,
                                 runner_mode: Literal['async', 'stream'] = 'async'):
    """
    è¾“å…¥[{"role": "user", "content": prompt}]æ ¼å¼prompt,è¾“å‡ºagentçš„resultç±»ï¼Œå¯ä»¥é€šè¿‡result.new_itemså±æ€§æ¥æŸ¥çœ‹å…¨éƒ¨çš„äº‹ä»¶ï¼›
    result.new_items[0].raw_itemï¼Œå¯ä»¥çœ‹å…·ä½“çš„å›å¤å†…å®¹ï¼›to_input_list()æ–¹æ³•ï¼Œå¯ä»¥ç›´æ¥å°†ç”¨æˆ·çš„è¾“å…¥å’Œæœ¬æ¬¡è¾“å‡ºç»“æœæ‹¼æ¥æˆä¸€ä¸ªæ¶ˆæ¯åˆ—è¡¨
    :param agent:
    :param input_items: list[dict],è¡¨ç¤ºè¾“å…¥çš„promptæ ¼å¼åˆ—è¡¨ï¼Œä¾‹å¦‚: [{"role": "user", "content": prompt}]
    :param runner_mode:
    :return:
    """
    result = None
    if runner_mode == 'async':
        result = await Runner.run(agent, input_items)
        print(Markdown(result.final_output))
    elif runner_mode == 'stream':
        result = Runner.run_streamed(agent, input_items)
        async for event in result.stream_events():
            if event.type == "raw_response_event" and isinstance(event.data, ResponseTextDeltaEvent):
                print(event.data.delta, end="", flush=True)
            elif event.type == "agent_updated_stream_event":
                print(f"Agent updated: {event.new_agent.name}")
                continue
            elif event.type == "run_item_stream_event":
                if event.item.type == "tool_call_item":
                    print("-- Tool was called")
                elif event.item.type == "tool_call_output_item":
                    print(f"-- Tool output: {event.item.output}")
                # elif event.item.type == "message_output_item": # å¦‚æœå®Œæˆåä¸€æ¬¡æ€§è¾“å‡º
                #     print(f"-- Message output:\n {ItemHelpers.text_message_output(event.item)}")
                else:
                    pass  # Ignore other event types
    return result


async def agents_chat_continuous(agent: Agent, runner_mode: Literal['async', 'stream'] = 'async',
                                 enable_fileloading: bool = False):
    """
    è¾“å…¥ç”¨æˆ·è¾“å…¥ï¼Œè¾“å‡ºagentçš„resultç±»ï¼Œå¯ä»¥é€šè¿‡result.new_itemså±æ€§æ¥æŸ¥çœ‹å…¨éƒ¨çš„äº‹ä»¶ï¼›
    result.new_items[0].raw_itemï¼Œå¯ä»¥çœ‹å…·ä½“çš„å›å¤å†…å®¹ï¼›to_input_list()æ–¹æ³•ï¼Œå¯ä»¥ç›´æ¥å°†ç”¨æˆ·çš„è¾“å…¥å’Œæœ¬æ¬¡è¾“å‡ºç»“æœæ‹¼æ¥æˆä¸€ä¸ªæ¶ˆæ¯åˆ—è¡¨
    :param agent:
    :param runner_mode:
    :param enable_fileloading: æŸäº›æ¨¡å‹éœ€è¦æ–‡ä»¶ä¸Šä¼ ï¼Œå½“ä¸éœ€è¦æ–‡ä»¶ä¸Šä¼ æ—¶ï¼Œå¯ä»¥é¿å…æ¯æ¬¡input()æ–‡ä»¶è·¯å¾„
    :return:
    """
    input_item = []
    result = None
    while True:
        contents = []
        msg_input = input("\nğŸ’¬ è¯·è¾“å…¥ä½ çš„æ¶ˆæ¯(è¾“å…¥quité€€å‡º):")
        if msg_input.lower() in ['exit', 'quit']:
            print("âœ… å¯¹è¯å·²ç»“æŸ")
            break
        if enable_fileloading:
            file_input = input("\nğŸ“ è¯·è¾“å…¥å›¾ç‰‡æˆ–è€…æ–‡æ¡£è·¯å¾„(è¾“å…¥quité€€å‡º):")
            file_input = file_input.strip("'\"")  # æ–‡ä»¶è·¯å¾„å»é™¤é¦–ä½å¼•å·ï¼Œå¦åˆ™ä¼špathlib.Pathè®¤ä¸ºå­—ç¬¦ä¸²
            file_path = pathlib.Path(file_input)
            if file_input not in ['cancel', 'no_file', 'quit']:
                if file_path.exists() and file_path.is_file():
                    if file_path.suffix.lower() in ['.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff', '.webp',
                                                    '.heic']:
                        img_item = load_img(file_input)
                        contents.append(img_item)
                        input_item.append({"role": "user", "content": contents})
                else:
                    print(f"âœ… å¯¹è¯å·²ç»“æŸ,{file_path.suffix.lower()}å›¾ç‰‡æ ¼å¼ä¸æ”¯æŒ")
                    break
            else:
                print("âœ… å¯¹è¯å·²ç»“æŸ, æ–‡æ¡£ä¸æ˜¯æ–‡ä»¶æˆ–è€…ä¸å­˜åœ¨")
        input_item.append({"role": "user", "content": msg_input})
        result = await agents_async_chat_once(agent=agent, input_items=input_item, runner_mode=runner_mode)
        input_item = result.to_input_list()
    return result


@function_tool
def folder_search(folder_path: str):
    """
    æœç´¢æŒ‡å®šæ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ï¼Œå¹¶è¾“å‡ºæ–‡ä»¶åˆ—è¡¨
    :param folder_path:
    :return:
    """
    files = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if
             os.path.isfile(os.path.join(folder_path, file))]
    return files


def base64_image(image_path):
    """
    è¯»å–æœ¬åœ°æ–‡ä»¶ï¼Œå¹¶ç¼–ç ä¸º Base64 æ ¼å¼
    """
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")


def load_img(image_path: str | pathlib.Path):
    """
    1) æ ¹æ®è·¯å¾„ï¼ŒåŠ è½½ä¸€å¼ å›¾ç‰‡æ–‡æ¡£ï¼Œè·å–å›¾ç‰‡æ–‡ä»¶åç¼€;
    2) å¯¹ä¸æ”¯æŒçš„æ–‡ä»¶åç¼€ï¼Œé”™è¯¯é€€å‡ºï¼Œå¹¶è¿”å›ä¸æ”¯æŒçš„å›¾åƒæ–‡æ¡£;
    3) å¯¹æ”¯æŒçš„å›¾ç‰‡æ–‡æ¡£ï¼Œè¿›è¡Œbase64ç¼–ç ;
    4) æŒ‰ç…§å›¾ç‰‡çš„åç¼€ï¼Œè¾“å‡ºQwen-VLæ¨¡å‹input_itemæ ¼å¼ï¼š{
                    "type": "image_url",
                    # éœ€è¦æ³¨æ„ï¼Œä¼ å…¥Base64ï¼Œå›¾åƒæ ¼å¼ï¼ˆå³image/{format}ï¼‰éœ€è¦ä¸æ”¯æŒçš„å›¾ç‰‡åˆ—è¡¨ä¸­çš„Content Typeä¿æŒä¸€è‡´ã€‚"f"æ˜¯å­—ç¬¦ä¸²æ ¼å¼åŒ–çš„æ–¹æ³•ã€‚
                    # PNGå›¾åƒï¼š  f"data:image/png;base64,{base64_image}"
                    # JPEGå›¾åƒï¼š f"data:image/jpeg;base64,{base64_image}"
                    # WEBPå›¾åƒï¼š f"data:image/webp;base64,{base64_image}"
                    "image_url": {"url": f"data:image/png;base64,{base64_image}"}
    :param image_path: å•å¼ å›¾ç‰‡ï¼Œæœ¬åœ°æ–‡ä»¶è·¯å¾„;æ”¯æŒçš„åç¼€ï¼š.bmp,.png,.jpe, .jpeg, .jpg,.tif,.tiff,.webp,.heic;
    :return: è¿”å›Qwen-VLè¦æ±‚çš„æœ¬åœ°å›¾ç‰‡æ–‡ä»¶ä¸Šä¼ æ ¼å¼;
    """
    supported_img = [".bmp", ".png", ".jpe", ".jpeg", ".jpg", ".tif", ".tiff", ".webp", ".heic"]
    jpg_variant = ['.jpe', '.jpeg', '.jpg']
    tif_variant = ['.tif', '.tiff']
    img_path_obj = pathlib.Path(image_path)
    img_format = img_path_obj.suffix
    if img_format not in supported_img:
        print(f"ä¸æ”¯æŒçš„å›¾ç‰‡æ ¼å¼ï¼š{img_format}")
        return None
    if not pathlib.Path.exists(img_path_obj):
        print(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼š{image_path}")
        return None
    base64_img = base64_image(image_path)
    if img_format in jpg_variant:
        img_format = "jpeg"
    elif img_format in tif_variant:
        img_format = "tiff"
    input_item = {
        # "type": "image_url", # qwençš„OpenAIæ ¼å¼,ä¸openai-agentä¸åŒ
        # "image_url": {"url": f"data:image/{img_format};base64,{base64_img}"} # qwençš„OpenAIæ ¼å¼,ä¸openai-agentä¸åŒ
        "type": "input_image",
        "detail": "auto",
        "image_url": f"data:image/{img_format};base64,{base64_img}"}  # openAI-Aentsæ ¼å¼
    return input_item


class mcp_stdio(BaseModel):
    command: str
    args: list[str]


class mcp_sse(BaseModel):
    url: str


class openAI_Agents_create:
    """
    åˆ›å»ºopenAI-Agents,å¯é€‰å·¥å…·,ä¾‹å¦‚æœç´¢,è‡ªå®šä¹‰function_tool, æµå¼è¾“å‡º;
    """

    def __init__(self, agent_name: str, instruction: str, model: str, base_url: str = None, api_key: str = None,
                 handoffs: list[Agent] = None, handoff_description: str = None, enable_thinking: bool = False,
                 enable_search: bool = True, force_search: bool = False, enable_source: bool = True,
                 enable_citation: bool = True, citation_format: bool = "[ref_<number>]", search_strategy="pro",
                 tool_choice: str = None, parallel_tool_calls: bool = False, tools: list = None,
                 custom_extra_body: dict = None,
                 ):
        """
        OpenAI-Agentsåˆå§‹åŒ–
        :param model: è­¬å¦‚: 'model': 'qwen-turbo-latest',   # è¾“å…¥0.0003å…ƒ;æ€è€ƒæ¨¡å¼0.006å…ƒ;éæ€è€ƒæ¨¡å¼0.0006å…ƒ
                            'model': 'qwq-plus-latest',   # è¾“å…¥0.0016å…ƒ;   è¾“å‡º0.004å…ƒ
                            'model': 'qwen-max-latest',   # è¾“å…¥0.0024å…ƒ;   è¾“å‡º0.0096å…ƒ
                            'model': 'qwen-plus-latest',  # è¾“å…¥0.0008å…ƒ;æ€è€ƒæ¨¡å¼0.016å…ƒ;éæ€è€ƒæ¨¡å¼0.002å…ƒ
                            'model': 'qwen-vl-plus-latest',è¾“å…¥:0.0015;è¾“å‡º:0.0045
        :param base_url: base_url, è­¬å¦‚:'http://localhost:8000/v1'
        :param api_key:  æ¨¡å‹api-key
        :param handoffs: åˆ†è¯Šagentåˆ—è¡¨
        :param handoff_description: A description of the agent. This is used when the agent is used as a handoff, so that an
    LLM knows what it does and when to invoke it
        :param enable_thinking: å¯¹äºQwenæ¨¡å‹ï¼Œä»…åœ¨streamæ‰“å¼€æ—¶ï¼Œä½¿ç”¨ï¼›
        :param enable_search: # å¼€å¯è”ç½‘æœç´¢çš„å‚æ•°
        :param force_search: # å¼ºåˆ¶å¼€å¯è”ç½‘æœç´¢
        :param enable_source: # ä½¿è¿”å›ç»“æœåŒ…å«æœç´¢æ¥æºçš„ä¿¡æ¯ï¼ŒOpenAI å…¼å®¹æ–¹å¼æš‚ä¸æ”¯æŒè¿”å›
        :param enable_citation: # å¼€å¯è§’æ ‡æ ‡æ³¨åŠŸèƒ½
        :param citation_format: # è§’æ ‡å½¢å¼ä¸º[ref_i]
        :param search_strategy: "pro"æ—¶,æ¨¡å‹å°†æœç´¢10æ¡äº’è”ç½‘ä¿¡æ¯
        :param instruction: ä¾‹å¦‚: "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©ç†ï¼ŒæŒ‰ç…§ç”¨æˆ·éœ€æ±‚ï¼Œä½ å…ˆç”»å›¾ï¼Œå†è¿è¡Œä»£ç ...."
        :param tools: åˆ—è¡¨,åŒ…å«è‡ªå®šä¹‰function_tool,æˆ–å…¶å®ƒå·¥å…·
        :param tool_choice: None, 'auto' ç­‰
        :param parallel_tool_calls: bool
        :param custom_extra_body: dict å½“custom_body != Noneæ—¶ï¼Œå°†è‡ªå®šä¹‰extra_body,

        """
        if api_key is None:
            api_key = os.getenv("DASHSCOPE_API_KEY")
        if base_url is None:
            base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"

        if custom_extra_body is None:
            extra_body = {
                "enable_thinking": enable_thinking,  # only support stream call
                "enable_search": enable_search,
                'search_options': {
                    "forced_search": force_search,  # å¼ºåˆ¶å¼€å¯è”ç½‘æœç´¢
                    "enable_source": enable_source,  # ä½¿è¿”å›ç»“æœåŒ…å«æœç´¢æ¥æºçš„ä¿¡æ¯ï¼ŒOpenAI å…¼å®¹æ–¹å¼æš‚ä¸æ”¯æŒè¿”å›
                    "enable_citation": enable_citation,  # å¼€å¯è§’æ ‡æ ‡æ³¨åŠŸèƒ½
                    "citation_format": citation_format,  # è§’æ ‡å½¢å¼ä¸º[ref_i]
                    "search_strategy": search_strategy  # "pro"æ—¶,æ¨¡å‹å°†æœç´¢10æ¡äº’è”ç½‘ä¿¡æ¯
                }
            }
        else:
            extra_body = custom_extra_body

        model_settings = ModelSettings(
            tool_choice=tool_choice,
            parallel_tool_calls=parallel_tool_calls,
            extra_body=extra_body, )

        self.agent_params = {
            'name': agent_name,
            'instructions': instruction,
            'model_settings': model_settings,
        }

        default_OpenAIModel = custom2default_openai_model(model=model,
                                                          base_url=base_url,
                                                          api_key=api_key,
                                                          )
        self.agent_params['model'] = default_OpenAIModel

        if tools is not None:
            self.agent_params['tools'] = tools
            # tools=[WebSearchTool(user_location={"type": "approximate", "city": "New York"})], # ç›®å‰åªæ”¯æŒopenAIçš„æ¨¡å‹

        if handoffs is not None:
            self.agent_params['handoffs'] = handoffs
        if handoff_description is not None:
            self.agent_params['handoff_description'] = handoff_description

        self.agent = Agent(**self.agent_params)
        self.instruction = instruction

    async def mcp_server_initialize(self, mcp_names: list[str] = None,
                                    mcp_params: list[dict] = None,
                                    mcp_io_methods: list[
                                        Literal["MCPServerStdio", "MCPServerSse", "MCPServerStreamableHttp"]] = None,
                                    mcp_added_instructions: list[str] = None):
        """
        åˆå§‹åŒ–mcp_server,å¹¶åˆå§‹åŒ–åŒ…å«mcp_serversçš„agent
        :param mcp_names: [mcp_name] ,å½“æœ‰mcp serveræ—¶ï¼Œé…ç½®mcp name; mcp_names/mcp_paramsåˆ—è¡¨ä¸­ä¸€ä¸€å¯¹åº”;
        :param mcp_params: [mcp_parm],å½“æœ‰mcp serveræ—¶ï¼Œé…ç½®mcp params: æ”¯æŒï¼Œ stdio, sse, streamableHttp;mcp_names/mcp_paramsåˆ—è¡¨ä¸­ä¸€ä¸€å¯¹åº”
        :param mcp_io_methods: å¯¹åº”æ¯ä¸€ä¸ªmcp server, stdio, sse, streamableHttp ä¸‰ç§ioä¼ è¾“æ–¹å¼é€‰ä¸€
        :param mcp_added_instructions: [mcp_added_instruction], åˆ—è¡¨
        :return:
        """
        # å¤„ç†mcp_serverçš„å‚æ•°
        if mcp_added_instructions is not None:
            self.agent_params['instructions'] = self.instruction.join(mcp_added_instructions)
        if mcp_names is not None and mcp_params is not None and mcp_io_methods is not None:
            self.agent_params['mcp_servers'] = []
            # ä½¿ç”¨ AsyncExitStack è‡ªåŠ¨ç®¡ç†å¤šä¸ªä¸Šä¸‹æ–‡é€€å‡º
            stack = AsyncExitStack()
            for mcp_name, mcp_param, mcp_io_method in zip(mcp_names, mcp_params, mcp_io_methods):
                if mcp_io_method == "MCPServerStdio":
                    # æ‰‹åŠ¨åˆ›å»ºå¹¶å¯åŠ¨server:
                    mcp_server = MCPServerStdio(name=mcp_name,
                                                cache_tools_list=True,
                                                params=mcp_param)
                elif mcp_io_method == "MCPServerSse":
                    # æ‰‹åŠ¨åˆ›å»ºå¹¶å¯åŠ¨server:
                    mcp_server = MCPServerSse(name=mcp_name,
                                              cache_tools_list=True,
                                              params=mcp_param)
                elif mcp_io_method == "MCPServerStreamableHttp":
                    # æ‰‹åŠ¨åˆ›å»ºå¹¶å¯åŠ¨server:
                    mcp_server = MCPServerStreamableHttp(name=mcp_name,
                                                         cache_tools_list=True,
                                                         params=mcp_param)
                else:
                    mcp_server = None
                # å¯åŠ¨server
                await mcp_server.connect()
                # åˆ›å»ºå¹¶è¿›å…¥æ‰€æœ‰ server ä¸Šä¸‹æ–‡
                stacked_mcp_server = await stack.enter_async_context(mcp_server)

                self.agent_params['mcp_servers'].append(stacked_mcp_server)
            self.agent = Agent(**self.agent_params)

    async def mcp_server_cleanup(self, ):
        mcp_servers = self.agent_params.get('mcp_servers', None)
        if mcp_servers is not None:
            for mcp_server in mcp_servers:
                try:
                    await mcp_server.cleanup()
                except Exception as e:
                    print(f"[WARNING] æ¸…ç† MCP Server æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                del self.agent_params['mcp_servers']

    async def async_chat_once(self, input_items: list[TResponseInputItem] | TResponseInputItem,
                              runner_mode: Literal['async', 'stream'] = 'async'):
        """
        è¾“å…¥[{"role": "user", "content": prompt}]æ ¼å¼prompt,è¾“å‡ºagentçš„resultç±»ï¼Œå¯ä»¥é€šè¿‡result.new_itemså±æ€§æ¥æŸ¥çœ‹å…¨éƒ¨çš„äº‹ä»¶ï¼›
        result.new_items[0].raw_itemï¼Œå¯ä»¥çœ‹å…·ä½“çš„å›å¤å†…å®¹ï¼›to_input_list()æ–¹æ³•ï¼Œå¯ä»¥ç›´æ¥å°†ç”¨æˆ·çš„è¾“å…¥å’Œæœ¬æ¬¡è¾“å‡ºç»“æœæ‹¼æ¥æˆä¸€ä¸ªæ¶ˆæ¯åˆ—è¡¨
        :param input_items: list[dict],è¡¨ç¤ºè¾“å…¥çš„promptæ ¼å¼åˆ—è¡¨ï¼Œä¾‹å¦‚: [{"role": "user", "content": prompt}]
        :param runner_mode:
        :return:
        """
        result = await agents_async_chat_once(agent=self.agent,
                                              input_items=input_items,
                                              runner_mode=runner_mode)
        return result

    async def chat_continuous(self, runner_mode: Literal['async', 'stream'] = 'async',
                              enable_fileloading: bool = False):
        result = await agents_chat_continuous(agent=self.agent, runner_mode=runner_mode,
                                              enable_fileloading=enable_fileloading)
        return result

    async def multi_mcp_chat_continuous(self, mcp_names: list[str] = None, mcp_params: list[dict] = None,
                                        mcp_io_methods: list[Literal[
                                            "MCPServerStdio", "MCPServerSse", "MCPServerStreamableHttp"]] = None,
                                        mcp_added_instructions: list[str] = None,
                                        runner_mode: Literal['async', 'stream'] = 'async',
                                        enable_fileloading: bool = False, ):
        # å¤„ç†mcp_serverçš„å‚æ•°
        if mcp_added_instructions is not None:
            self.agent_params['instructions'] = self.instruction.join(mcp_added_instructions)
        if mcp_names is not None and mcp_params is not None and mcp_io_methods is not None:
            # ä½¿ç”¨ AsyncExitStack è‡ªåŠ¨ç®¡ç†å¤šä¸ªä¸Šä¸‹æ–‡é€€å‡º
            async with AsyncExitStack() as stack:
                self.agent_params['mcp_servers'] = []
                for mcp_name, mcp_param, mcp_io_method in zip(mcp_names, mcp_params, mcp_io_methods):
                    # åˆ›å»ºå¹¶è¿›å…¥æ‰€æœ‰ mcp_server ä¸Šä¸‹æ–‡
                    if mcp_io_method == "MCPServerStdio":
                        mcp_server = MCPServerStdio(name=mcp_name,
                                                    cache_tools_list=True,
                                                    params=mcp_param)
                    elif mcp_io_method == "MCPServerSse":
                        mcp_server = MCPServerSse(name=mcp_name,
                                                  cache_tools_list=True,
                                                  params=mcp_param)
                    elif mcp_io_method == "MCPServerStreamableHttp":
                        mcp_server = MCPServerStreamableHttp(name=mcp_name,
                                                             cache_tools_list=True,
                                                             params=mcp_param)
                    else:
                        mcp_server = None

                    stacked_mcp_server = await stack.enter_async_context(mcp_server)
                    self.agent_params['mcp_servers'].append(stacked_mcp_server)
                self.agent = Agent(**self.agent_params)
                result = await agents_chat_continuous(agent=self.agent, runner_mode=runner_mode,
                                                      enable_fileloading=enable_fileloading)
                return result


# 2
# é€šä¹‰åƒé—®VLï¼šqwen-vl-plus-latestï¼Œæ¨¡å‹å¯ä»¥æ ¹æ®æ‚¨ä¼ å…¥çš„å›¾ç‰‡æ¥è¿›è¡Œå›ç­” è¾“å…¥:0.0015;è¾“å‡º:0.0045
# å›¾åƒé—®ç­”ï¼šæè¿°å›¾åƒä¸­çš„å†…å®¹æˆ–è€…å¯¹å…¶è¿›è¡Œåˆ†ç±»æ‰“æ ‡ï¼Œå¦‚è¯†åˆ«äººç‰©ã€åœ°ç‚¹ã€èŠ±é¸Ÿé±¼è™«ç­‰ã€‚
# æ•°å­¦é¢˜ç›®è§£ç­”ï¼šè§£ç­”å›¾åƒä¸­çš„æ•°å­¦é—®é¢˜ï¼Œé€‚ç”¨äºä¸­å°å­¦ã€å¤§å­¦ä»¥åŠæˆäººæ•™è‚²é˜¶æ®µã€‚
# è§†é¢‘ç†è§£ï¼šåˆ†æè§†é¢‘å†…å®¹ï¼Œå¦‚å¯¹å…·ä½“äº‹ä»¶è¿›è¡Œå®šä½å¹¶è·å–æ—¶é—´æˆ³ï¼Œæˆ–ç”Ÿæˆå…³é”®æ—¶é—´æ®µçš„æ‘˜è¦ã€‚
# ç‰©ä½“å®šä½ï¼šå®šä½å›¾åƒä¸­çš„ç‰©ä½“ï¼Œè¿”å›å¤–è¾¹ç•ŒçŸ©å½¢æ¡†çš„å·¦ä¸Šè§’ã€å³ä¸‹è§’åæ ‡æˆ–è€…ä¸­å¿ƒç‚¹åæ ‡ã€‚
# æ–‡æ¡£è§£æï¼šå°†å›¾åƒç±»çš„æ–‡æ¡£ï¼ˆå¦‚æ‰«æä»¶/å›¾ç‰‡PDFï¼‰è§£æä¸º QwenVL HTMLæ ¼å¼ï¼Œè¯¥æ ¼å¼ä¸ä»…èƒ½ç²¾å‡†è¯†åˆ«æ–‡æœ¬ï¼Œè¿˜èƒ½è·å–å›¾åƒã€è¡¨æ ¼ç­‰å…ƒç´ çš„ä½ç½®ä¿¡æ¯ã€‚
# æ–‡å­—è¯†åˆ«ä¸ä¿¡æ¯æŠ½å–ï¼šè¯†åˆ«å›¾åƒä¸­çš„æ–‡å­—ã€å…¬å¼ï¼Œæˆ–è€…æŠ½å–ç¥¨æ®ã€è¯ä»¶ã€è¡¨å•ä¸­çš„ä¿¡æ¯ï¼Œæ”¯æŒæ ¼å¼åŒ–è¾“å‡ºæ–‡æœ¬ï¼›å¯è¯†åˆ«çš„è¯­è¨€æœ‰ä¸­æ–‡ã€è‹±è¯­ã€æ—¥è¯­ã€éŸ©è¯­ã€é˜¿æ‹‰ä¼¯è¯­ã€è¶Šå—è¯­ã€æ³•è¯­ã€å¾·è¯­ã€æ„å¤§åˆ©è¯­ã€è¥¿ç­ç‰™è¯­å’Œä¿„è¯­ã€‚
# 3
# é€šä¹‰åƒé—®OCRï¼šqwen-vl-ocr-latestï¼Œï¼ˆè¾“å…¥è¾“å‡ºï¼š0.005ï¼‰ï¼Œæ˜¯æ–‡å­—æå–ä¸“æœ‰æ¨¡å‹ï¼Œä¸“æ³¨äºæ–‡æ¡£ã€è¡¨æ ¼ã€è¯•é¢˜ã€æ‰‹å†™ä½“æ–‡å­—ç­‰ç±»å‹å›¾åƒçš„æ–‡å­—æå–èƒ½åŠ›ã€‚å®ƒèƒ½å¤Ÿè¯†åˆ«å¤šç§æ–‡å­—ï¼Œç›®å‰æ”¯æŒçš„è¯­è¨€æœ‰ï¼šæ±‰è¯­ã€è‹±è¯­ã€é˜¿æ‹‰ä¼¯è¯­ã€æ³•è¯­ã€å¾·è¯­ã€æ„å¤§åˆ©è¯­ã€æ—¥è¯­ã€éŸ©è¯­ã€è‘¡è„ç‰™è¯­ã€ä¿„è¯­ã€è¥¿ç­ç‰™è¯­ã€è¶Šå—è¯­ã€‚
# æ”¯æŒåœ¨æ–‡å­—æå–å‰ï¼Œå¯¹å›¾åƒè¿›è¡Œæ—‹è½¬çŸ«æ­£ï¼Œé€‚åˆå›¾åƒå€¾æ–œçš„åœºæ™¯ã€‚#
# æ–°å¢å…­ç§å†…ç½®çš„OCRä»»åŠ¡ï¼Œåˆ†åˆ«æ˜¯é€šç”¨æ–‡å­—è¯†åˆ«ã€ä¿¡æ¯æŠ½å–ã€æ–‡æ¡£è§£æã€è¡¨æ ¼è§£æã€å…¬å¼è¯†åˆ«ã€å¤šè¯­è¨€è¯†åˆ«ã€‚#
# æœªè®¾ç½®å†…ç½®ä»»åŠ¡æ—¶ï¼Œæ”¯æŒç”¨æˆ·è¾“å…¥Promptè¿›è¡ŒæŒ‡å¼•ï¼›å¦‚è®¾ç½®äº†å†…ç½®ä»»åŠ¡æ—¶ï¼Œä¸ºä¿è¯è¯†åˆ«æ•ˆæœï¼Œæ¨¡å‹å†…éƒ¨ä¼šä½¿ç”¨ä»»åŠ¡æŒ‡å®šçš„Promptã€‚
# ä»…DashScope SDKæ”¯æŒå¯¹å›¾åƒè¿›è¡Œæ—‹è½¬çŸ«æ­£å’Œè®¾ç½®å†…ç½®ä»»åŠ¡ã€‚å¦‚éœ€ä½¿ç”¨OpenAI SDKè¿›è¡Œå†…ç½®çš„OCRä»»åŠ¡ï¼Œéœ€è¦æ‰‹åŠ¨å¡«å†™ä»»åŠ¡æŒ‡å®šçš„Promptè¿›è¡Œå¼•å¯¼ã€‚

QwenVL_model = 'qwen-vl-plus-latest'
base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"
QwenVL_agent_instruction = '''
    æ‚¨æ˜¯ä¸€ä¸ªåŠ©äººä¸ºä¹çš„åŠ©æ‰‹ï¼Œå¯ä»¥æ ¹æ®ä¼ å…¥çš„å›¾ç‰‡æ¥è¿›è¡Œ:
    1)å›¾åƒé—®ç­”ï¼šæè¿°å›¾åƒä¸­çš„å†…å®¹æˆ–è€…å¯¹å…¶è¿›è¡Œåˆ†ç±»æ‰“æ ‡ï¼Œå¦‚è¯†åˆ«äººç‰©ã€åœ°ç‚¹ã€èŠ±é¸Ÿé±¼è™«ç­‰ã€‚
    2)æ•°å­¦é¢˜ç›®è§£ç­”ï¼šè§£ç­”å›¾åƒä¸­çš„æ•°å­¦é—®é¢˜ï¼Œé€‚ç”¨äºä¸­å°å­¦ã€å¤§å­¦ä»¥åŠæˆäººæ•™è‚²é˜¶æ®µã€‚
    3)è§†é¢‘ç†è§£ï¼šåˆ†æè§†é¢‘å†…å®¹ï¼Œå¦‚å¯¹å…·ä½“äº‹ä»¶è¿›è¡Œå®šä½å¹¶è·å–æ—¶é—´æˆ³ï¼Œæˆ–ç”Ÿæˆå…³é”®æ—¶é—´æ®µçš„æ‘˜è¦ã€‚
    4)ç‰©ä½“å®šä½ï¼šå®šä½å›¾åƒä¸­çš„ç‰©ä½“ï¼Œè¿”å›å¤–è¾¹ç•ŒçŸ©å½¢æ¡†çš„å·¦ä¸Šè§’ã€å³ä¸‹è§’åæ ‡æˆ–è€…ä¸­å¿ƒç‚¹åæ ‡ã€‚
    5)æ–‡æ¡£è§£æï¼šå°†å›¾åƒç±»çš„æ–‡æ¡£ï¼ˆå¦‚æ‰«æä»¶/å›¾ç‰‡PDFï¼‰è§£æä¸º QwenVL HTMLæ ¼å¼ï¼Œè¯¥æ ¼å¼ä¸ä»…èƒ½ç²¾å‡†è¯†åˆ«æ–‡æœ¬ï¼Œè¿˜èƒ½è·å–å›¾åƒã€è¡¨æ ¼ç­‰å…ƒç´ çš„ä½ç½®ä¿¡æ¯ã€‚
    6)æ–‡å­—è¯†åˆ«ä¸ä¿¡æ¯æŠ½å–ï¼šè¯†åˆ«å›¾åƒä¸­çš„æ–‡å­—ã€å…¬å¼ï¼Œæˆ–è€…æŠ½å–ç¥¨æ®ã€è¯ä»¶ã€è¡¨å•ä¸­çš„ä¿¡æ¯ï¼Œæ”¯æŒæ ¼å¼åŒ–è¾“å‡ºæ–‡æœ¬ï¼›å¯è¯†åˆ«çš„è¯­è¨€æœ‰ä¸­æ–‡ã€è‹±è¯­ã€æ—¥è¯­ã€éŸ©è¯­ã€é˜¿æ‹‰ä¼¯è¯­ã€è¶Šå—è¯­ã€æ³•è¯­ã€å¾·è¯­ã€æ„å¤§åˆ©è¯­ã€è¥¿ç­ç‰™è¯­å’Œä¿„è¯­ã€‚
    ä½ åªå¯¹å¸¦æœ‰å›¾ç‰‡çš„promptï¼Œåšå‡ºå“åº”ã€‚
    '''


# Qwen-MTæ¨¡å‹æ˜¯åŸºäºé€šä¹‰åƒé—®æ¨¡å‹ä¼˜åŒ–çš„æœºå™¨ç¿»è¯‘å¤§è¯­è¨€æ¨¡å‹ï¼Œæ“…é•¿ä¸­è‹±äº’è¯‘ã€ä¸­æ–‡ä¸å°è¯­ç§äº’è¯‘ã€è‹±æ–‡ä¸å°è¯­ç§äº’è¯‘
# qwen-mt-plus  0.015å…ƒ/0.045å…ƒ;
# qwen-mt-turbo 0.001å…ƒ/0.003å…ƒ
# ä¸æ”¯æŒæŒ‡å®š System Messageï¼Œä¹Ÿä¸æ”¯æŒå¤šè½®å¯¹è¯ï¼›messages æ•°ç»„ä¸­æœ‰ä¸”ä»…æœ‰ä¸€ä¸ª User Messageï¼Œç”¨äºæŒ‡å®šéœ€è¦ç¿»è¯‘çš„è¯­å¥ã€‚
# å¦‚æœæ‚¨å¸Œæœ›ç¿»è¯‘çš„é£æ ¼æ›´ç¬¦åˆæŸä¸ªé¢†åŸŸçš„ç‰¹æ€§ï¼Œå¦‚æ³•å¾‹ã€æ”¿åŠ¡é¢†åŸŸç¿»è¯‘ç”¨è¯­åº”å½“ä¸¥è‚ƒæ­£å¼ï¼Œç¤¾äº¤é¢†åŸŸç”¨è¯­åº”å½“å£è¯­åŒ–ï¼Œå¯ä»¥ç”¨ä¸€æ®µè‡ªç„¶è¯­è¨€æ–‡æœ¬æè¿°æ‚¨çš„é¢†åŸŸï¼Œå°†å…¶æä¾›ç»™å¤§æ¨¡å‹ä½œä¸ºæç¤ºã€‚# é¢†åŸŸæç¤ºè¯­å¥æš‚æ—¶åªæ”¯æŒè‹±æ–‡ã€‚

class Term(BaseModel):
    source: str
    target: str


def Qwen_MT_func(prompt: str, model: str = 'qwen-mt-turbo', api_key: str = None, source_lang: str = 'auto',
                 target_lang: str = 'English', terms: list[Term] = None, tm_list: list[Term] = None,
                 domains: str = None):
    """
    Qwen-MTæ¨¡å‹æ˜¯åŸºäºé€šä¹‰åƒé—®æ¨¡å‹ä¼˜åŒ–çš„æœºå™¨ç¿»è¯‘å¤§è¯­è¨€æ¨¡å‹ï¼Œæ“…é•¿ä¸­è‹±äº’è¯‘ã€ä¸­æ–‡ä¸å°è¯­ç§äº’è¯‘ã€è‹±æ–‡ä¸å°è¯­ç§äº’è¯‘;åœ¨å¤šè¯­è¨€äº’è¯‘çš„åŸºç¡€ä¸Šï¼Œæä¾›æœ¯è¯­å¹²é¢„ã€é¢†åŸŸæç¤ºã€è®°å¿†åº“ç­‰èƒ½åŠ›ï¼Œæå‡æ¨¡å‹åœ¨å¤æ‚åº”ç”¨åœºæ™¯ä¸‹çš„ç¿»è¯‘æ•ˆæœã€‚
    :param prompt: str, è¾“å…¥çš„prompt
    :param model: str, æ‚¨å¯¹ç¿»è¯‘è´¨é‡æœ‰è¾ƒé«˜è¦æ±‚ï¼Œå»ºè®®é€‰æ‹©qwen-mt-plusæ¨¡å‹ï¼›å¦‚æœæ‚¨å¸Œæœ›ç¿»è¯‘é€Ÿåº¦æ›´å¿«æˆ–æˆæœ¬æ›´ä½ï¼Œå»ºè®®é€‰æ‹©qwen-mt-turboæ¨¡å‹
    :param api_key: str, é˜¿é‡Œäº‘ç™¾ç‚¼API Key
    :param source_lang: str, æºè¯­è¨€
    :param target_lang: str, ç›®æ ‡è¯­è¨€
    :param terms: list[dict], æŠ€æœ¯æœ¯è¯­å¯ä»¥æå‰ç¿»è¯‘ï¼Œå¹¶å°†å…¶æä¾›ç»™Qwen-MTæ¨¡å‹ä½œä¸ºå‚è€ƒï¼›æ¯ä¸ªæœ¯è¯­æ˜¯ä¸€ä¸ªJSONå¯¹è±¡ï¼ŒåŒ…å«æœ¯è¯­å’Œç¿»è¯‘è¿‡çš„æœ¯è¯­ä¿¡æ¯ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š{"source": "æœ¯è¯­", "target": "æå‰ç¿»è¯‘å¥½çš„æœ¯è¯­"}
    :param tm_list: list[dict], å¦‚æœæ‚¨å·²ç»æœ‰æ ‡å‡†çš„åŒè¯­å¥å¯¹å¹¶ä¸”å¸Œæœ›å¤§æ¨¡å‹åœ¨åç»­ç¿»è¯‘æ—¶èƒ½å‚è€ƒè¿™äº›æ ‡å‡†è¯‘æ–‡ç»™å‡ºç»“æœï¼Œå¯ä»¥ä½¿ç”¨ç¿»è¯‘è®°å¿†åŠŸèƒ½ï¼›æ¯ä¸ªJSONå¯¹è±¡åŒ…å«æºè¯­å¥ä¸å¯¹åº”çš„å·²ç¿»è¯‘çš„è¯­å¥ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š{"source": "æºè¯­å¥","target": "å·²ç¿»è¯‘çš„è¯­å¥"}
    :param domains: str, å¦‚æœæ‚¨å¸Œæœ›ç¿»è¯‘çš„é£æ ¼æ›´ç¬¦åˆæŸä¸ªé¢†åŸŸçš„ç‰¹æ€§ï¼Œå¯ä»¥ç”¨ä¸€æ®µè‡ªç„¶è¯­è¨€æ–‡æœ¬æè¿°æ‚¨çš„é¢†åŸŸ(æš‚æ—¶åªæ”¯æŒè‹±æ–‡)
    :return: str, ç¿»è¯‘ç»“æœ
    """
    if api_key is None:
        api_key = os.getenv("DASHSCOPE_API_KEY")

    client = OpenAI(
        # è‹¥æ²¡æœ‰é…ç½®ç¯å¢ƒå˜é‡ï¼Œè¯·ç”¨é˜¿é‡Œäº‘ç™¾ç‚¼API Keyå°†ä¸‹è¡Œæ›¿æ¢ä¸ºï¼šapi_key="sk-xxx",
        api_key=api_key,
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    )
    messages = [{"role": "user", "content": prompt}]

    translation_options = {
        "source_lang": source_lang,
        "target_lang": target_lang
    }
    if terms is not None:
        translation_options['terms'] = terms
    if tm_list is not None:
        translation_options['tm_list'] = tm_list
    if domains is not None:
        translation_options['domains'] = domains

    completion = client.chat.completions.create(
        model=model,
        messages=messages,
        extra_body={
            "translation_options": translation_options
        }
    )
    # print(completion.choices[0].gradio_message.content)
    return completion.choices[0].message.content


@function_tool
def _Qwen_MT_func(prompt: str, model: str = 'qwen-mt-turbo', api_key: str = None, source_lang: str = 'auto',
                  target_lang: str = 'English', terms: list[Term] = None, tm_list: list[Term] = None,
                  domains: str = None):
    """
    Qwen-MTæ¨¡å‹æ˜¯åŸºäºé€šä¹‰åƒé—®æ¨¡å‹ä¼˜åŒ–çš„æœºå™¨ç¿»è¯‘å¤§è¯­è¨€æ¨¡å‹ï¼Œæ“…é•¿ä¸­è‹±äº’è¯‘ã€ä¸­æ–‡ä¸å°è¯­ç§äº’è¯‘ã€è‹±æ–‡ä¸å°è¯­ç§äº’è¯‘;åœ¨å¤šè¯­è¨€äº’è¯‘çš„åŸºç¡€ä¸Šï¼Œæä¾›æœ¯è¯­å¹²é¢„ã€é¢†åŸŸæç¤ºã€è®°å¿†åº“ç­‰èƒ½åŠ›ï¼Œæå‡æ¨¡å‹åœ¨å¤æ‚åº”ç”¨åœºæ™¯ä¸‹çš„ç¿»è¯‘æ•ˆæœã€‚
    :param prompt: str, è¾“å…¥çš„prompt
    :param model: str, æ‚¨å¯¹ç¿»è¯‘è´¨é‡æœ‰è¾ƒé«˜è¦æ±‚ï¼Œå»ºè®®é€‰æ‹©qwen-mt-plusæ¨¡å‹ï¼›å¦‚æœæ‚¨å¸Œæœ›ç¿»è¯‘é€Ÿåº¦æ›´å¿«æˆ–æˆæœ¬æ›´ä½ï¼Œå»ºè®®é€‰æ‹©qwen-mt-turboæ¨¡å‹
    :param api_key: str, é˜¿é‡Œäº‘ç™¾ç‚¼API Key
    :param source_lang: str, æºè¯­è¨€
    :param target_lang: str, ç›®æ ‡è¯­è¨€
    :param terms: list[dict], æŠ€æœ¯æœ¯è¯­å¯ä»¥æå‰ç¿»è¯‘ï¼Œå¹¶å°†å…¶æä¾›ç»™Qwen-MTæ¨¡å‹ä½œä¸ºå‚è€ƒï¼›æ¯ä¸ªæœ¯è¯­æ˜¯ä¸€ä¸ªJSONå¯¹è±¡ï¼ŒåŒ…å«æœ¯è¯­å’Œç¿»è¯‘è¿‡çš„æœ¯è¯­ä¿¡æ¯ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š{"source": "æœ¯è¯­", "target": "æå‰ç¿»è¯‘å¥½çš„æœ¯è¯­"}
    :param tm_list: list[dict], å¦‚æœæ‚¨å·²ç»æœ‰æ ‡å‡†çš„åŒè¯­å¥å¯¹å¹¶ä¸”å¸Œæœ›å¤§æ¨¡å‹åœ¨åç»­ç¿»è¯‘æ—¶èƒ½å‚è€ƒè¿™äº›æ ‡å‡†è¯‘æ–‡ç»™å‡ºç»“æœï¼Œå¯ä»¥ä½¿ç”¨ç¿»è¯‘è®°å¿†åŠŸèƒ½ï¼›æ¯ä¸ªJSONå¯¹è±¡åŒ…å«æºè¯­å¥ä¸å¯¹åº”çš„å·²ç¿»è¯‘çš„è¯­å¥ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š{"source": "æºè¯­å¥","target": "å·²ç¿»è¯‘çš„è¯­å¥"}
    :param domains: str, å¦‚æœæ‚¨å¸Œæœ›ç¿»è¯‘çš„é£æ ¼æ›´ç¬¦åˆæŸä¸ªé¢†åŸŸçš„ç‰¹æ€§ï¼Œå¯ä»¥ç”¨ä¸€æ®µè‡ªç„¶è¯­è¨€æ–‡æœ¬æè¿°æ‚¨çš„é¢†åŸŸ(æš‚æ—¶åªæ”¯æŒè‹±æ–‡)
    :return: str, ç¿»è¯‘ç»“æœ
    """
    result = Qwen_MT_func(prompt, model, api_key, source_lang, target_lang, terms, tm_list, domains)
    return result


@function_tool
def save2file(file_path: pathlib.Path, content):
    """
    ç”¨äºå°†LLMçš„è¾“å‡ºï¼Œä¾ç…§ä¸€å®šçš„æ ¼å¼å†™å…¥æœ¬åœ°æ–‡ä»¶file_name
    :param file_path:
    :param content:
    :return:
    """
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(content)


async def main():  # ä¾¿äºå¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†ï¼Œå»ºè®®å¤šè¯­å¥æ”¾å…¥å¼‚æ­¥å‡½æ•°ä¸­ï¼Œä¸€èµ·æ‰§è¡Œ

    mcp_names = ['file_system']
    mcp_params = [{
        "command": "npx",
        "args": [
            "-y",
            "@modelcontextprotocol/server-filesystem",
            ".",
        ]}]
    mcp_io_methods = ["MCPServerStdio"]

    QwenVL_agent = openAI_Agents_create(agent_name='é€šä¹‰åƒé—®è§†è§‰ç†è§£æ™ºèƒ½ä½“',
                                        instruction=QwenVL_agent_instruction,
                                        model=QwenVL_model,
                                        base_url=None,
                                        api_key=None,
                                        tools=[save2file],
                                        handoff_description="å½“promptæœ‰å›¾ç‰‡æ—¶,ä½¿ç”¨QwenVLæ¨¡å‹è¿›è¡Œè§†è§‰æ¨ç†,å¹¶ä¸”å¿…è¦æ—¶ï¼ŒæŒ‰è¦æ±‚å°†çº¦å®šçš„å†…å®¹å­˜å…¥æœ¬åœ°æ–‡ä»¶"
                                        )

    Qwen_model = 'qwen-turbo-latest'
    Qwen_model_instruction = """
        ä½ æ˜¯ä¸€ååŠ©äººä¸ºä¹çš„åŠ©æ‰‹,
        1)å½“promptä¸­æœ‰æ–‡ä»¶æ—¶ï¼Œè¯·handoffè‡³è§†è§‰æ¨ç†æ¨¡å‹;
        2)å¦åˆ™ï¼Œå°±ç›´æ¥å›ç­”é—®é¢˜;
        3) å¿…è¦æ—¶ï¼Œå¯ä»¥å°†çº¦å®šçš„å†…å®¹å­˜å…¥æœ¬åœ°æ–‡ä»¶ã€‚
        """
    handoff_description = """
        æœ¬æ¨¡å‹ä»…ä»…å¤„ç†ä¸å¸¦æœ‰æ–‡ä»¶çš„prompt;å½“promptå›¾ç‰‡æ–‡ä»¶æ—¶ï¼Œè¯·handoffè‡³è§†è§‰æ¨ç†æ¨¡å‹ï¼Œå¹¶ç»™å‡ºç»“æœã€‚
        """
    Qwen3_agent = openAI_Agents_create(agent_name='é€šä¹‰åƒé—®æ™ºèƒ½ä½“(general)',
                                       instruction=Qwen_model_instruction,
                                       model=Qwen_model,
                                       base_url=None,
                                       api_key=None,
                                       tools=[save2file],
                                       handoffs=[QwenVL_agent.agent],
                                       handoff_description=handoff_description

                                       )
    # è¿è¡Œä¸»åç¨‹
    await Qwen3_agent.chat_continuous(runner_mode='stream', enable_fileloading=True)
    # await QwenVL_agent.multi_mcp_chat_continuous(runner_mode='async', enable_fileloading=False,
    #                                                    mcp_names=mcp_names,
    #                                                    mcp_params=mcp_params,
    #                                                    mcp_io_methods=mcp_io_methods)


if __name__ == '__main__':
    # Windows ä¸Šæ¨èä½¿ç”¨ ProactorEventLoopï¼Œä½†éœ€ç¡®ä¿äº‹ä»¶å¾ªç¯æ­£ç¡®å…³é—­
    policy = asyncio.WindowsProactorEventLoopPolicy()
    asyncio.set_event_loop_policy(policy)

    asyncio.run(main())
