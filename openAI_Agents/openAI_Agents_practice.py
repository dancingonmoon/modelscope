import os
import asyncio
from openai import AsyncOpenAI
from openai.types.responses import ResponseTextDeltaEvent
from agents import OpenAIChatCompletionsModel, Agent, Runner, set_default_openai_client, set_tracing_disabled, \
    function_tool
from agents.model_settings import ModelSettings
from rich import print
from rich.markdown import Markdown
from typing import Literal
import base64
import pathlib


# ç”±äºAgents SDKé»˜è®¤æ”¯æŒçš„æ¨¡å‹æ˜¯OpenAIçš„GPTç³»åˆ—ï¼Œå› æ­¤åœ¨ä¿®æ”¹åº•å±‚æ¨¡å‹çš„æ—¶å€™ï¼Œéœ€è¦å°†custom_client è®¾ç½®ä¸ºï¼šset_default_openai_client(external_client)

def custom2default_openai_model(model: str, base_url: str, api_key: str, ):
    custom_client = AsyncOpenAI(base_url=base_url, api_key=api_key)
    set_default_openai_client(custom_client)
    # we disable tracing under the assumption that you don't have an API key
    # from platform.openai.com. If you do have one, you can either set the `OPENAI_API_KEY` env var
    # or call set_tracing_export_api_key() to set a tracing specific key
    set_tracing_disabled(disabled=True)  # ä¸åœ¨platform.openai.comä¸Štrace
    default_openai_model = OpenAIChatCompletionsModel(model=model, openai_client=custom_client)
    return default_openai_model


async def agents_async_chat_once(agent: Agent, input_items: list[dict],
                                 runner_mode: Literal['async', 'stream'] = 'async'):
    """
    è¾“å…¥[{"role": "user", "content": prompt}]æ ¼å¼prompt,è¾“å‡ºagentçš„resultç±»ï¼Œå¯ä»¥é€šè¿‡result.new_itemså±æ€§æ¥æŸ¥çœ‹å…¨éƒ¨çš„äº‹ä»¶ï¼›
    result.new_items[0].raw_itemï¼Œå¯ä»¥çœ‹å…·ä½“çš„å›å¤å†…å®¹ï¼›to_input_list()æ–¹æ³•ï¼Œå¯ä»¥ç›´æ¥å°†ç”¨æˆ·çš„è¾“å…¥å’Œæœ¬æ¬¡è¾“å‡ºç»“æœæ‹¼æ¥æˆä¸€ä¸ªæ¶ˆæ¯åˆ—è¡¨
    :param agent:
    :param input_items: list[dict],è¡¨ç¤ºè¾“å…¥çš„promptæ ¼å¼åˆ—è¡¨ï¼Œä¾‹å¦‚: [{"role": "user", "content": prompt}]
    :param runner_mode:
    :return:
    """
    result = None
    if runner_mode == 'async':
        result = await Runner.run(agent, input_items)
        print(Markdown(result.final_output))
    elif runner_mode == 'stream':
        result = Runner.run_streamed(agent, input_items)
        async for event in result.stream_events():
            if event.type == "raw_response_event" and isinstance(event.data, ResponseTextDeltaEvent):
                print(event.data.delta, end="", flush=True)
    return result


async def agents_chat_continuous(agent: Agent, runner_mode: Literal['async', 'stream'] = 'async'):
    input_item = []
    while True:
        user_input = input("\nğŸ’¬ è¯·è¾“å…¥ä½ çš„æ¶ˆæ¯(è¾“å…¥quité€€å‡º):")
        if user_input.lower() in ['exit', 'quit']:
            print("âœ… å¯¹è¯å·²ç»“æŸ")
            break
        input_item.append({"role": "user", "content": user_input})
        result = await agents_async_chat_once(agent=agent, input_items=input_item, runner_mode=runner_mode)
        input_item = result.to_input_list()


@function_tool
def folder_search(query: str, folder_path: str):
    """
    æœç´¢æŒ‡å®šæ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ï¼Œå¹¶è¾“å‡ºæ–‡ä»¶åˆ—è¡¨
    :param query:
    :param folder_path:
    :return:
    """
    files = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if
             os.path.isfile(os.path.join(folder_path, file))]
    return files


def base64_image(image_path):
    """
    è¯»å–æœ¬åœ°æ–‡ä»¶ï¼Œå¹¶ç¼–ç ä¸º Base64 æ ¼å¼
    """
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")


@function_tool
def load_img(image_path):
    """
    1) æ ¹æ®è·¯å¾„ï¼ŒåŠ è½½ä¸€å¼ å›¾ç‰‡æ–‡æ¡£ï¼Œè·å–å›¾ç‰‡æ–‡ä»¶åç¼€;
    2) å¯¹ä¸æ”¯æŒçš„æ–‡ä»¶åç¼€ï¼Œé”™è¯¯é€€å‡ºï¼Œå¹¶è¿”å›ä¸æ”¯æŒçš„å›¾åƒæ–‡æ¡£;
    3) å¯¹æ”¯æŒçš„å›¾ç‰‡æ–‡æ¡£ï¼Œè¿›è¡Œbase64ç¼–ç ;
    4) æŒ‰ç…§å›¾ç‰‡çš„åç¼€ï¼Œè¾“å‡ºQwen-VLæ¨¡å‹input_itemæ ¼å¼ï¼š{
                    "type": "image_url",
                    # éœ€è¦æ³¨æ„ï¼Œä¼ å…¥Base64ï¼Œå›¾åƒæ ¼å¼ï¼ˆå³image/{format}ï¼‰éœ€è¦ä¸æ”¯æŒçš„å›¾ç‰‡åˆ—è¡¨ä¸­çš„Content Typeä¿æŒä¸€è‡´ã€‚"f"æ˜¯å­—ç¬¦ä¸²æ ¼å¼åŒ–çš„æ–¹æ³•ã€‚
                    # PNGå›¾åƒï¼š  f"data:image/png;base64,{base64_image}"
                    # JPEGå›¾åƒï¼š f"data:image/jpeg;base64,{base64_image}"
                    # WEBPå›¾åƒï¼š f"data:image/webp;base64,{base64_image}"
                    "image_url": {"url": f"data:image/png;base64,{base64_image}"}
    :param image_path: å•å¼ å›¾ç‰‡ï¼Œæœ¬åœ°æ–‡ä»¶è·¯å¾„;æ”¯æŒçš„åç¼€ï¼š.bmp,.png,.jpe, .jpeg, .jpg,.tif,.tiff,.webp,.heic;
    :return: è¿”å›Qwen-VLè¦æ±‚çš„æœ¬åœ°å›¾ç‰‡æ–‡ä»¶ä¸Šä¼ æ ¼å¼;
    """
    supported_img = [".bmp", ".png", ".jpe", ".jpeg", ".jpg", ".tif", ".tiff", ".webp", ".heic"]
    jpg_variant = ['.jpe', '.jpeg', '.jpg']
    tif_variant = ['.tif', '.tiff']
    img_format = pathlib.Path(image_path).suffix
    if img_format not in supported_img:
        print(f"ä¸æ”¯æŒçš„å›¾ç‰‡æ ¼å¼ï¼š{img_format}")
        return None
    if not pathlib.Path.exists(image_path):
        print(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼š{image_path}")
        return None
    base64_img = base64_image(image_path)
    if img_format in jpg_variant:
        img_format = "jpeg"
    elif img_format in tif_variant:
        img_format = "tiff"
    input_item = {
        "type": "image_url",
        "image_url": {"url": f"data:image/{img_format};base64,{base64_img}"}
    }
    return input_item


# é€šä¹‰åƒé—®VLï¼šqwen-vl-plus-latestï¼Œæ¨¡å‹å¯ä»¥æ ¹æ®æ‚¨ä¼ å…¥çš„å›¾ç‰‡æ¥è¿›è¡Œå›ç­” è¾“å…¥:0.0015;è¾“å‡º:0.0045
# å›¾åƒé—®ç­”ï¼šæè¿°å›¾åƒä¸­çš„å†…å®¹æˆ–è€…å¯¹å…¶è¿›è¡Œåˆ†ç±»æ‰“æ ‡ï¼Œå¦‚è¯†åˆ«äººç‰©ã€åœ°ç‚¹ã€èŠ±é¸Ÿé±¼è™«ç­‰ã€‚
# æ•°å­¦é¢˜ç›®è§£ç­”ï¼šè§£ç­”å›¾åƒä¸­çš„æ•°å­¦é—®é¢˜ï¼Œé€‚ç”¨äºä¸­å°å­¦ã€å¤§å­¦ä»¥åŠæˆäººæ•™è‚²é˜¶æ®µã€‚
# è§†é¢‘ç†è§£ï¼šåˆ†æè§†é¢‘å†…å®¹ï¼Œå¦‚å¯¹å…·ä½“äº‹ä»¶è¿›è¡Œå®šä½å¹¶è·å–æ—¶é—´æˆ³ï¼Œæˆ–ç”Ÿæˆå…³é”®æ—¶é—´æ®µçš„æ‘˜è¦ã€‚
# ç‰©ä½“å®šä½ï¼šå®šä½å›¾åƒä¸­çš„ç‰©ä½“ï¼Œè¿”å›å¤–è¾¹ç•ŒçŸ©å½¢æ¡†çš„å·¦ä¸Šè§’ã€å³ä¸‹è§’åæ ‡æˆ–è€…ä¸­å¿ƒç‚¹åæ ‡ã€‚
# æ–‡æ¡£è§£æï¼šå°†å›¾åƒç±»çš„æ–‡æ¡£ï¼ˆå¦‚æ‰«æä»¶/å›¾ç‰‡PDFï¼‰è§£æä¸º QwenVL HTMLæ ¼å¼ï¼Œè¯¥æ ¼å¼ä¸ä»…èƒ½ç²¾å‡†è¯†åˆ«æ–‡æœ¬ï¼Œè¿˜èƒ½è·å–å›¾åƒã€è¡¨æ ¼ç­‰å…ƒç´ çš„ä½ç½®ä¿¡æ¯ã€‚
# æ–‡å­—è¯†åˆ«ä¸ä¿¡æ¯æŠ½å–ï¼šè¯†åˆ«å›¾åƒä¸­çš„æ–‡å­—ã€å…¬å¼ï¼Œæˆ–è€…æŠ½å–ç¥¨æ®ã€è¯ä»¶ã€è¡¨å•ä¸­çš„ä¿¡æ¯ï¼Œæ”¯æŒæ ¼å¼åŒ–è¾“å‡ºæ–‡æœ¬ï¼›å¯è¯†åˆ«çš„è¯­è¨€æœ‰ä¸­æ–‡ã€è‹±è¯­ã€æ—¥è¯­ã€éŸ©è¯­ã€é˜¿æ‹‰ä¼¯è¯­ã€è¶Šå—è¯­ã€æ³•è¯­ã€å¾·è¯­ã€æ„å¤§åˆ©è¯­ã€è¥¿ç­ç‰™è¯­å’Œä¿„è¯­ã€‚

VL_agent = Agent(
    name="VL",
    instructions='''
    ä½ æ˜¯ä¸€ä¸ªåŠ©äººä¸ºä¹çš„åŠ©æ‰‹ï¼Œå¯ä»¥æ ¹æ®æ‚¨ä¼ å…¥çš„å›¾ç‰‡æ¥è¿›è¡Œ:
    1)å›¾åƒé—®ç­”ï¼šæè¿°å›¾åƒä¸­çš„å†…å®¹æˆ–è€…å¯¹å…¶è¿›è¡Œåˆ†ç±»æ‰“æ ‡ï¼Œå¦‚è¯†åˆ«äººç‰©ã€åœ°ç‚¹ã€èŠ±é¸Ÿé±¼è™«ç­‰ã€‚
    2)æ•°å­¦é¢˜ç›®è§£ç­”ï¼šè§£ç­”å›¾åƒä¸­çš„æ•°å­¦é—®é¢˜ï¼Œé€‚ç”¨äºä¸­å°å­¦ã€å¤§å­¦ä»¥åŠæˆäººæ•™è‚²é˜¶æ®µã€‚
    3)è§†é¢‘ç†è§£ï¼šåˆ†æè§†é¢‘å†…å®¹ï¼Œå¦‚å¯¹å…·ä½“äº‹ä»¶è¿›è¡Œå®šä½å¹¶è·å–æ—¶é—´æˆ³ï¼Œæˆ–ç”Ÿæˆå…³é”®æ—¶é—´æ®µçš„æ‘˜è¦ã€‚
    4)ç‰©ä½“å®šä½ï¼šå®šä½å›¾åƒä¸­çš„ç‰©ä½“ï¼Œè¿”å›å¤–è¾¹ç•ŒçŸ©å½¢æ¡†çš„å·¦ä¸Šè§’ã€å³ä¸‹è§’åæ ‡æˆ–è€…ä¸­å¿ƒç‚¹åæ ‡ã€‚
    5)æ–‡æ¡£è§£æï¼šå°†å›¾åƒç±»çš„æ–‡æ¡£ï¼ˆå¦‚æ‰«æä»¶/å›¾ç‰‡PDFï¼‰è§£æä¸º QwenVL HTMLæ ¼å¼ï¼Œè¯¥æ ¼å¼ä¸ä»…èƒ½ç²¾å‡†è¯†åˆ«æ–‡æœ¬ï¼Œè¿˜èƒ½è·å–å›¾åƒã€è¡¨æ ¼ç­‰å…ƒç´ çš„ä½ç½®ä¿¡æ¯ã€‚
    6)æ–‡å­—è¯†åˆ«ä¸ä¿¡æ¯æŠ½å–ï¼šè¯†åˆ«å›¾åƒä¸­çš„æ–‡å­—ã€å…¬å¼ï¼Œæˆ–è€…æŠ½å–ç¥¨æ®ã€è¯ä»¶ã€è¡¨å•ä¸­çš„ä¿¡æ¯ï¼Œæ”¯æŒæ ¼å¼åŒ–è¾“å‡ºæ–‡æœ¬ï¼›å¯è¯†åˆ«çš„è¯­è¨€æœ‰ä¸­æ–‡ã€è‹±è¯­ã€æ—¥è¯­ã€éŸ©è¯­ã€é˜¿æ‹‰ä¼¯è¯­ã€è¶Šå—è¯­ã€æ³•è¯­ã€å¾·è¯­ã€æ„å¤§åˆ©è¯­ã€è¥¿ç­ç‰™è¯­å’Œä¿„è¯­ã€‚
    ''',
    model=custom2default_openai_model(model="qwen-vl-plus-latest",
                                      base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
                                      api_key=os.getenv("DASHSCOPE_API_KEY"),
                                      ),
    model_settings=ModelSettings(
                      tool_choice='auto',
                      parallel_tool_calls=False,
                      extra_body={
                          # "enable_thinking": True, # only support stream call
                          "enable_search": True,
                          'search_options': {
                              "forced_search": False,  # å¼ºåˆ¶å¼€å¯è”ç½‘æœç´¢
                              "enable_source": False,  # ä½¿è¿”å›ç»“æœåŒ…å«æœç´¢æ¥æºçš„ä¿¡æ¯ï¼ŒOpenAI å…¼å®¹æ–¹å¼æš‚ä¸æ”¯æŒè¿”å›
                              "enable_citation": True,  # å¼€å¯è§’æ ‡æ ‡æ³¨åŠŸèƒ½
                              "citation_format": "[ref_<number>]",  # è§’æ ‡å½¢å¼ä¸º[ref_i]
                              "search_strategy": "pro"  # "pro"æ—¶,æ¨¡å‹å°†æœç´¢10æ¡äº’è”ç½‘ä¿¡æ¯
                          }
                      }
                  ),
                  tools=[load_img]

)

# é€šä¹‰åƒé—®OCRï¼šqwen-vl-ocr-latestï¼Œï¼ˆè¾“å…¥è¾“å‡ºï¼š0.005ï¼‰ï¼Œæ˜¯æ–‡å­—æå–ä¸“æœ‰æ¨¡å‹ï¼Œä¸“æ³¨äºæ–‡æ¡£ã€è¡¨æ ¼ã€è¯•é¢˜ã€æ‰‹å†™ä½“æ–‡å­—ç­‰ç±»å‹å›¾åƒçš„æ–‡å­—æå–èƒ½åŠ›ã€‚å®ƒèƒ½å¤Ÿè¯†åˆ«å¤šç§æ–‡å­—ï¼Œç›®å‰æ”¯æŒçš„è¯­è¨€æœ‰ï¼šæ±‰è¯­ã€è‹±è¯­ã€é˜¿æ‹‰ä¼¯è¯­ã€æ³•è¯­ã€å¾·è¯­ã€æ„å¤§åˆ©è¯­ã€æ—¥è¯­ã€éŸ©è¯­ã€è‘¡è„ç‰™è¯­ã€ä¿„è¯­ã€è¥¿ç­ç‰™è¯­ã€è¶Šå—è¯­ã€‚
# æ”¯æŒåœ¨æ–‡å­—æå–å‰ï¼Œå¯¹å›¾åƒè¿›è¡Œæ—‹è½¬çŸ«æ­£ï¼Œé€‚åˆå›¾åƒå€¾æ–œçš„åœºæ™¯ã€‚#
# æ–°å¢å…­ç§å†…ç½®çš„OCRä»»åŠ¡ï¼Œåˆ†åˆ«æ˜¯é€šç”¨æ–‡å­—è¯†åˆ«ã€ä¿¡æ¯æŠ½å–ã€æ–‡æ¡£è§£æã€è¡¨æ ¼è§£æã€å…¬å¼è¯†åˆ«ã€å¤šè¯­è¨€è¯†åˆ«ã€‚#
# æœªè®¾ç½®å†…ç½®ä»»åŠ¡æ—¶ï¼Œæ”¯æŒç”¨æˆ·è¾“å…¥Promptè¿›è¡ŒæŒ‡å¼•ï¼›å¦‚è®¾ç½®äº†å†…ç½®ä»»åŠ¡æ—¶ï¼Œä¸ºä¿è¯è¯†åˆ«æ•ˆæœï¼Œæ¨¡å‹å†…éƒ¨ä¼šä½¿ç”¨ä»»åŠ¡æŒ‡å®šçš„Promptã€‚
# ä»…DashScope SDKæ”¯æŒå¯¹å›¾åƒè¿›è¡Œæ—‹è½¬çŸ«æ­£å’Œè®¾ç½®å†…ç½®ä»»åŠ¡ã€‚å¦‚éœ€ä½¿ç”¨OpenAI SDKè¿›è¡Œå†…ç½®çš„OCRä»»åŠ¡ï¼Œéœ€è¦æ‰‹åŠ¨å¡«å†™ä»»åŠ¡æŒ‡å®šçš„Promptè¿›è¡Œå¼•å¯¼ã€‚


# Qwen2.5-VLæ¨¡å‹æ”¯æŒå°†å›¾åƒç±»çš„æ–‡æ¡£ï¼ˆå¦‚æ‰«æä»¶/å›¾ç‰‡PDFï¼‰è§£æä¸º QwenVL HTMLæ ¼å¼ï¼Œè¯¥æ ¼å¼ä¸ä»…èƒ½ç²¾å‡†è¯†åˆ«æ–‡æœ¬ï¼Œè¿˜èƒ½è·å–å›¾åƒã€è¡¨æ ¼ç­‰å…ƒç´ çš„ä½ç½®ä¿¡æ¯ã€‚
# PromptæŠ€å·§ï¼šæ‚¨éœ€è¦åœ¨æç¤ºè¯ä¸­å¼•å¯¼æ¨¡å‹è¾“å‡ºQwenVL HTMLï¼Œå¦åˆ™å°†è§£æä¸ºä¸å¸¦ä½ç½®ä¿¡æ¯çš„HTMLæ ¼å¼çš„æ–‡æœ¬
if __name__ == '__main__':
    # model = 'qwen-plus'
    model = 'qwen-turbo-latest'
    base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"
    instruction = instructions = "ä½ æ˜¯ä¸€ååŠ©äººä¸ºä¹çš„åŠ©æ‰‹ï¼Œå¹¶ä¸”æœç´¢å¹¶è¾“å‡ºæŒ‡å®šæ–‡ä»¶å¤¹ä¸‹çš„æ–‡ä»¶"
    default_OpenAIModel = custom2default_openai_model(model=model,
                                                      base_url=base_url,
                                                      api_key=os.getenv("DASHSCOPE_API_KEY"),
                                                      )
    agent = Agent(name="my_assistant", instructions=instruction,
                  model=default_OpenAIModel,
                  model_settings=ModelSettings(
                      tool_choice='auto',
                      parallel_tool_calls=False,
                      extra_body={
                          # "enable_thinking": True, # only support stream call
                          "enable_search": True,
                          'search_options': {
                              "forced_search": False,  # å¼ºåˆ¶å¼€å¯è”ç½‘æœç´¢
                              "enable_source": False,  # ä½¿è¿”å›ç»“æœåŒ…å«æœç´¢æ¥æºçš„ä¿¡æ¯ï¼ŒOpenAI å…¼å®¹æ–¹å¼æš‚ä¸æ”¯æŒè¿”å›
                              "enable_citation": True,  # å¼€å¯è§’æ ‡æ ‡æ³¨åŠŸèƒ½
                              "citation_format": "[ref_<number>]",  # è§’æ ‡å½¢å¼ä¸º[ref_i]
                              "search_strategy": "pro"  # "pro"æ—¶,æ¨¡å‹å°†æœç´¢10æ¡äº’è”ç½‘ä¿¡æ¯
                          }
                      }
                  ),
                  # tools=[WebSearchTool(user_location={"type": "approximate", "city": "New York"})], # ç›®å‰åªæ”¯æŒopenAIçš„æ¨¡å‹
                  tools=[folder_search]
                  )
    # è¿è¡Œä¸»åç¨‹
    asyncio.run(agents_chat_continuous(agent, runner_mode='stream'), debug=False)
