{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5203c84-e1fc-44d5-8fb4-4b49292f7081",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T07:34:35.701515Z",
     "iopub.status.busy": "2023-08-22T07:34:35.701166Z",
     "iopub.status.idle": "2023-08-22T07:34:39.420930Z",
     "shell.execute_reply": "2023-08-22T07:34:39.420376Z",
     "shell.execute_reply.started": "2023-08-22T07:34:35.701497Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 15:34:37.126673: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-22 15:34:37.135180: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-22 15:34:37.202722: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-22 15:34:37.203818: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-22 15:34:37.873849: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/conda/lib/python3.8/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n",
      "[2023-08-22 15:34:39,185] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# generator = pipeline(task=\"automatic-speech-recognition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2d45c9-8276-4424-a89f-debf0bc7407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "988f566a-df91-43ab-9e93-ae2410bd6d7b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-08-22T09:16:58.700153Z",
     "iopub.status.busy": "2023-08-22T09:16:58.699714Z",
     "iopub.status.idle": "2023-08-22T09:17:13.022005Z",
     "shell.execute_reply": "2023-08-22T09:17:13.021423Z",
     "shell.execute_reply.started": "2023-08-22T09:16:58.700127Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator = pipeline(model=\"openai/whisper-large\")\n",
    "# generator(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b8c24fa-f0d8-41bf-994c-38f67e4c93ea",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-08-22T09:18:15.843360Z",
     "iopub.status.busy": "2023-08-22T09:18:15.842975Z",
     "iopub.status.idle": "2023-08-22T09:18:15.846800Z",
     "shell.execute_reply": "2023-08-22T09:18:15.846277Z",
     "shell.execute_reply.started": "2023-08-22T09:18:15.843329Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(file):\n",
    "    return generator(file, language='chinese'  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc791278-ef39-4363-9183-13e0c61e2052",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2023-08-22T08:45:48.338590Z",
     "iopub.status.busy": "2023-08-22T08:45:48.338231Z",
     "iopub.status.idle": "2023-08-22T08:46:00.528875Z",
     "shell.execute_reply": "2023-08-22T08:46:00.528335Z",
     "shell.execute_reply.started": "2023-08-22T08:45:48.338568Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "# from datasets import load_dataset\n",
    "\n",
    "# load model and processor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large\")\n",
    "# model.config.forced_decoder_ids = None\n",
    "model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"chinese\", task=\"transcribe\")\n",
    "# load dummy dataset and read audio files\n",
    "def test(sample):\n",
    "    ds = load_dataset(sample)\n",
    "    sample = ds[0][\"audio\"]\n",
    "    input_features = processor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"], return_tensors=\"pt\").input_features \n",
    "    \n",
    "    # generate token ids\n",
    "    predicted_ids = model.generate(input_features)\n",
    "    # decode token ids to text\n",
    "    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=False)\n",
    "    #['<|startoftranscript|><|en|><|transcribe|><|notimestamps|> Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.<|endoftext|>']\n",
    "    \n",
    "    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "    #[' Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5382ae33-0523-4766-8d32-124e2ee878d0",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-08-22T07:36:14.930288Z",
     "iopub.status.busy": "2023-08-22T07:36:14.929959Z",
     "iopub.status.idle": "2023-08-22T07:36:16.088534Z",
     "shell.execute_reply": "2023-08-22T07:36:16.088006Z",
     "shell.execute_reply.started": "2023-08-22T07:36:14.930270Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eeb7bc2e-0318-4446-9059-ab8d63304f0d",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-08-22T09:18:19.913551Z",
     "iopub.status.busy": "2023-08-22T09:18:19.913194Z",
     "iopub.status.idle": "2023-08-22T09:18:21.989927Z",
     "shell.execute_reply": "2023-08-22T09:18:21.989419Z",
     "shell.execute_reply.started": "2023-08-22T09:18:19.913532Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## 测试whisper模型\")\n",
    "    with gr.Row():\n",
    "        inp = gr.Audio(source=\"microphone\",label=\"麦克风\",show_label=True,type='filepath')\n",
    "        out = gr.Textbox()\n",
    "    btn = gr.Button(\"Run\")\n",
    "    btn.click(fn=test, inputs=inp, outputs=out)\n",
    "\n",
    "demo.launch(show_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486d0e08-138a-4069-a260-e0312166d02a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
