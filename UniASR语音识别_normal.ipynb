{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a9e0e9-6dbd-4c61-aae0-9fb4cf165e96",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "\n",
    "inference_16k_pipline = pipeline(\n",
    "    task=Tasks.auto_speech_recognition,\n",
    "    # model='damo/speech_UniASR_asr_2pass-zh-cn-16k-common-vocab8358-tensorflow1-offline') #  offline\n",
    "    # model='damo/speech_UniASR_asr_2pass-zh-cn-16k-common-vocab8358-tensorflow1-online') # online\n",
    "    # model='speech_UniASR-large_asr_2pass-zh-cn-16k-common-vocab8358-tensorflow1-offline' # offline large\n",
    "    # model='damo/speech_paraformer-large_asr_nat-zh-cn-16k-aishell1-vocab8404-pytorch' # parafomer offline\n",
    "    model='damo/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch/summary' # paraformer 长音频\n",
    "\n",
    "# rec_result = inference_16k_pipline(audio_in='https://modelscope.oss-cn-beijing.aliyuncs.com/test/audios/asr_example.wav')\n",
    "# print(rec_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad7dd17-2d78-427a-a3a8-609b32000441",
   "metadata": {},
   "source": [
    "输入音频支持wav与pcm格式音频，以wav格式输入为例，支持以下几种输入方式：\n",
    "* wav文件路径，例如：data/test/audios/asr_example.wav\n",
    "* pcm文件路径，例如：data/test/audios/asr_example.pcm\n",
    "* wav文件url，例如：https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_zh.wav\n",
    "* wav二进制数据，格式bytes，例如：用户直接从文件里读出bytes数据或者是麦克风录出bytes数据。\n",
    "* 已解析的audio音频，例如：audio, rate = soundfile.read(\"asr_example_zh.wav\")，类型为numpy.ndarray或者torch.Tensor。\n",
    "\n",
    "识别结果输出路径结构如下：\n",
    "```\n",
    "tree output_dir/\n",
    "output_dir/\n",
    "└── 1best_recog\n",
    "    ├── rtf\n",
    "    ├── score\n",
    "    ├── text\n",
    "    └── time_stamp\n",
    "\n",
    "1 directory, 4 files\n",
    "```\n",
    "rtf：计算过程耗时统计\n",
    "score：识别路径得分\n",
    "text：语音识别结果文件\n",
    "time_stamp：时间戳结果文件\n",
    "\n",
    "ASR、VAD、PUNC模型自由组合\n",
    "可根据使用需求对VAD和PUNC标点模型进行自由组合，使用方式如下：\n",
    "```python\n",
    "inference_pipeline = pipeline(\n",
    "    task=Tasks.auto_speech_recognition,\n",
    "    model='damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch',\n",
    "    vad_model='damo/speech_fsmn_vad_zh-cn-16k-common-pytorch',\n",
    "    punc_model='damo/punc_ct-transformer_zh-cn-common-vocab272727-pytorch',\n",
    ")\n",
    "```\n",
    "如需加入LM模型，可增加配置lm_model='damo/speech_transformer_lm_zh-cn-common-vocab8404-pytorch'。\n",
    "\n",
    "长音频版本模型中集成了VAD、ASR、标点模型，若不使用VAD或标点模型，可设置参数vad_model=\"\"或punc_model=\"\"，具体使用方式可参考[文档](https://github.com/alibaba-damo-academy/FunASR/discussions/134)，例如：\n",
    "```python\n",
    "inference_pipeline = pipeline(\n",
    "    task=Tasks.auto_speech_recognition,\n",
    "    model='damo/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch',\n",
    "    vad_model='',\n",
    "    punc_model='',\n",
    ")\n",
    "```\n",
    "长音频版本模型默认开启时间戳，若不使用时间戳，可通过传入参数param_dict['use_timestamp'] = False关闭时间戳，使用方式如下：\n",
    "```python\n",
    "param_dict['use_timestamp'] = False\n",
    "rec_result = inference_pipeline(audio_in='https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_vad_punc_example.wav', param_dict=param_dict)\n",
    "\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34c5e1f1-31c7-4e54-8e39-d2d3498466a5",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2023-10-09T03:56:11.816718Z",
     "iopub.status.busy": "2023-10-09T03:56:11.816398Z",
     "iopub.status.idle": "2023-10-09T03:56:11.819617Z",
     "shell.execute_reply": "2023-10-09T03:56:11.819180Z",
     "shell.execute_reply.started": "2023-10-09T03:56:11.816701Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Paraformer_longaudio_model(use_vad_model=True,use_punc_model=True,use_lm_model=False):\n",
    "    \n",
    "    if use_vad_model:\n",
    "        vad_model='damo/speech_fsmn_vad_zh-cn-16k-common-pytorch'\n",
    "    else:\n",
    "        vad_model=''\n",
    "        \n",
    "    if use_punc_model:\n",
    "        punc_model='damo/punc_ct-transformer_zh-cn-common-vocab272727-pytorch'\n",
    "    else:\n",
    "        punc_model=''\n",
    "        \n",
    "    if use_lm_model:\n",
    "        inference_pipeline = pipeline(\n",
    "            task=Tasks.auto_speech_recognition,\n",
    "            # defaults to combine VAD, ASR and PUNC\n",
    "            model='damo/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch',\n",
    "            vad_model=vad_model,\n",
    "            punc_model=punc_model,\n",
    "            lm_model='damo/speech_transformer_lm_zh-cn-common-vocab8404-pytorch',\n",
    "            lm_weight=0.15,\n",
    "            beam_size=10,\n",
    "            )\n",
    "    else:\n",
    "        inference_pipeline = pipeline(\n",
    "            task=Tasks.auto_speech_recognition,\n",
    "            # defaults to combine VAD, ASR and PUNC\n",
    "            model='damo/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch',\n",
    "            vad_model=vad_model,\n",
    "            punc_model=punc_model,\n",
    "            )           \n",
    "        \n",
    "    return inference_pipeline #这里先输出模型, 以避免后续模型重复生成;\n",
    "\n",
    "def Paraformer_longaudio_recognition(audio_data,use_timestamp=True,)\n",
    "    \"\"\"\n",
    "    audio_data: 为输入音频,可以wav,二进制数据(bytes);url    \n",
    "    \"\"\"\n",
    "    param_dict['use_timestamp'] = use_timestamp\n",
    "    rec_result = inference_pipeline(audio_in=audio_data, param_dict=param_dict)\n",
    "    \n",
    "    return rec_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35c3b61-8b59-4a02-a55b-110143bfa64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  \n",
    "    with gr.Blocks(\n",
    "        theme=\"soft\",\n",
    "        title=\"UniASR语音实时识别\",\n",
    "    ) as demo:\n",
    "        gr.Markdown(\n",
    "            \"\"\"[**语音识别**](https://www.modelscope.cn/models/damo/speech_paraformer-large_asr_nat-zh-cn-16k-aishell1-vocab8404-pytorch/summary)\n",
    "                [**长语音模型**](https://www.modelscope.cn/models/damo/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch/summary)\n",
    "            > 1. 录音,或者上传音频wav格式\n",
    "            > 1. 选择是否使用 vad(voice activity detection), punc(标点), lm (NNLM) 诸模型\n",
    "            > 1. 点击,\"一键识别\",输出语音文字\n",
    "            \"\"\")\n",
    "        with gr.row():\n",
    "            with gr.column(variant='panel'):\n",
    "                inp0 = gr.Radio(\n",
    "                    choices=[\"microphone\", \"upload\"],\n",
    "                    value=\"upload\",\n",
    "                    type=\"value\",\n",
    "                    label=\"选择音频来源\",\n",
    "                    show_label=True,\n",
    "                    )\n",
    "                inp1 = gr.Audio(\n",
    "                    source=\"upload\",\n",
    "                    type=\"filepath\",\n",
    "                    show_label=True,\n",
    "                    interactive=True,\n",
    "                    )\n",
    "                inp2 = gr.CheckboxGroup([\"VAD\", \"PUNC\",\"NNLM\"], label=\"请选择是否使用下面模型\",\n",
    "                                        value=[\"VAD\", \"PUNC\"],show_label=True )\n",
    "                \n",
    "        img_numpy = inp0.change(image_source, inputs=inp0, outputs=inp1)\n",
    "        out = gr.Text(label='车辆类别,识别车牌号', show_copy_button=True,show_label=True,\n",
    "                     placeholder=\"['小型汽车'],['浙A88888']\")\n",
    "        submit_button = gr.Button(value='提交')\n",
    "        submit_button.click(VehiclePlate_Recognition,img_numpy,out)\n",
    "        \n",
    "        \n",
    "        demo.queue()\n",
    "        demo.launch(show_error=True, share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
